{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to find, load and process snRNA-seq data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import anndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gene network analysis is a method designed to identify sub-networks (modules) of correlated genes, which are likely to be co-expressed.\n",
    "#This can be helpful in identification of sub-networks (modules) of genes that contribute to disease.\n",
    "#In this example, we will cover how to create a pairwise correlation matrix of genes, as well as how to associate them with disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we will cover how to find, load and process the snRNA-seq data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acquire snRNA-seq data from cellxgene portal: https://cellxgene.cziscience.com/collections/180bff9c-c8a5-4539-b13b-ddbc00d643e6\n",
    "#Chosen microglia cell type to focus on from this paper: Molecular characterization of selectively vulnerable neurons in Alzheimer's Disease\n",
    "#https://www.nature.com/articles/s41593-020-00764-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For this tutorial, we will be using an open access freely available dataset that has been generated from microglia of the entorhinal cortex within the brain.\n",
    "#This dataset is available from the cellxgene portal, accessible here: https://cellxgene.cziscience.com/collections/180bff9c-c8a5-4539-b13b-ddbc00d643e6 entitled \"Molecular characterization of selectively vulnerable neurons in Alzheimerâ€™s Disease: EC microglia\".\n",
    "#SnRNA-seq was performed for Controls and donors with Alzheimer's Disease.\n",
    "#This dataset was chosen due to its small size and compatability with the purpose of the pipeline.\n",
    "#This data will be available in the data/test/ directory.\n",
    "#The generated dataset is stored in h5ad format.\n",
    "#By the end of this section, we will have loaded and explored the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start by downloading the dataset from the original portal.\n",
    "# URL of the dataset\n",
    "url = \"https://datasets.cellxgene.cziscience.com/1f0cd8ed-94c6-440c-bd5b-bad55e2666b1.h5ad\"\n",
    "\n",
    "# Destination path where the dataset will be saved\n",
    "destination_path = \"/shared/as8020/recode/mic_leng21.h5ad\"\n",
    "\n",
    "# Download the dataset\n",
    "wget.download(url, destination_path)\n",
    "\n",
    "#Alternatively, the dataset can be found in the dataset/test/ directory saved as mic_leng21.h5ad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in the test dataset\n",
    "mic = sc.read('dataset/mic_leng21.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect the loaded data\n",
    "mic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the gene names are in the correct format of gene symbols and not Ensembl IDs which are also common.\n",
    "mic.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As can be seen from the gene features dataframe, they have currently used the Ensembl gene naming system.\n",
    "#However, this isn't helpful for our analyses as they are not intuitively easy to interpret, instead you would need to research each Ensembl ID to identify that particular gene's name and function.\n",
    "#From the second column feature_name, it appears that the original authors have converted the Ensembl IDs to gene symbol names.\n",
    "\n",
    "#Let's go ahead and map the values in the feature_name column to the rownames of the dataframe:\n",
    "# Set the \"feature_name\" column as the index (row names)\n",
    "mic.var.set_index(\"feature_name\", drop = False, inplace=True)\n",
    "\n",
    "#It is important to note that not all Ensembl IDs map to Gene symbol names, as can be seen within rows 3 and 5 within the top of the dataframe.\n",
    "#Therefore, since there is not a mapping for all Ensembl IDs, we shall remove these rows from the dataframe as they will be difficult to interpret in subsequent analyses.\n",
    "# Filter rows where the index does not start with \"ENSG\" i.e. the Ensembl IDs.\n",
    "# Define the condition for filtering genes\n",
    "filter_genes = ~mic.var.index.str.startswith(\"ENSG\")  # Exclude genes starting with \"ENSG\"\n",
    "filter_genes\n",
    "\n",
    "# Filter genes based on the condition\n",
    "mic = mic[:, filter_genes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "mic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "mic.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As can be seen, the number of genes have now reduced as any rows with Ensembl IDs have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Also calculate the highly variable genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating highly variable genes on gene expression data that has not been log-transformed or normalized appropriately can lead to issues, including the presence of infinity values.\n",
    "#Log transformation is a common preprocessing step for scRNA-seq data, especially when dealing with count data, to stabilize the variance and make the data more amenable to downstream analysis. \n",
    "#It helps to mitigate the impact of high expression values and reduce the influence of technical noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log normalize the gene expression data\n",
    "sc.pp.log1p(mic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate highly variable genes\n",
    "sc.pp.highly_variable_genes(mic, n_top_genes = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "mic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets save the filtered object\n",
    "mic.write_h5ad('dataset/mic_leng21_filtered.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will now explore the associated metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "mic.obs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As can be seen, this dataset contains 5572 cells and 32743 genes.\n",
    "#It also has relevant metadata in the obs section, such as BraakStage. \n",
    "#The metadata may need to be encoded into the correct format for subsequent analyses, so let's have a look at the current format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "mic.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets create a separate dataframe with the metadata information as this will be needed for the correlation analysis.\n",
    "#Currently we want to create a copy of the metadata so as not to alter the original adata object.\n",
    "metadata = mic.obs.copy()\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are many columns that are not needed.\n",
    "#Let's remove uninteresting columns\n",
    "columns_to_remove = ['SampleID', 'SampleBatch',\n",
    "       'initialClusterAssignments',\n",
    "       'subclusterAssignment', 'tissue_ontology_term_id',\n",
    "       'cell_type_ontology_term_id', 'assay_ontology_term_id',\n",
    "       'disease_ontology_term_id', 'self_reported_ethnicity_ontology_term_id',\n",
    "       'development_stage_ontology_term_id', 'sex_ontology_term_id',\n",
    "       'is_primary_data', 'organism_ontology_term_id', 'suspension_type',\n",
    "       'tissue_type', 'cell_type', 'assay', 'organism',\n",
    "       'tissue', 'self_reported_ethnicity',\n",
    "       'observation_joinid' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.drop(columns=columns_to_remove, inplace = True) #Set inplace=True to modify the DataFrame in place. If you set inplace=False or omit it, the drop() method will return a new DataFrame with the specified columns removed, leaving the original DataFrame unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "mic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From investigating the metadata dataframe, BraakStage, nUMI, nGene and seurat.subclusters are all numerical, whilst disease, sex and development_stage are all character strings.\n",
    "#The columns with character strings will need to be reformatted appropriately so that they can be correlated against.\n",
    "#Lets first identify the unique labels within each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['sex'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looks like there are only male participants. Since there are only male differences, this column can also be removed, since we will not be able to investigate sex differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_remove = 'sex'\n",
    "metadata.drop(columns=column_to_remove, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's have a look at the disease variable\n",
    "metadata['disease'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The disease column can be encoded into a binary variable:\n",
    "metadata['AD'] = metadata['disease'].apply(lambda x: 1 if x == \"Alzheimer disease\" else 0)\n",
    "metadata['Normal'] = metadata['disease'].apply(lambda x: 1 if x == \"normal\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets sort out the development_stage column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['development_stage'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There appear to be 8 categories. Lets numerically encode them\n",
    "# Recode development_stage\n",
    "development_stage_mapping = {\n",
    "    '50-year-old human stage': 50,\n",
    "    '60-year-old human stage': 60,\n",
    "    '71-year-old human stage': 71,\n",
    "    '72-year-old human stage': 72,\n",
    "    '77-year-old human stage': 77,\n",
    "    '80 year-old and over human stage': 80,\n",
    "    '82-year-old human stage': 82,\n",
    "    '87-year-old human stage': 87\n",
    "}\n",
    "metadata['development_stage'] = metadata['development_stage'].map(development_stage_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the disease column as it is no longer necessary\n",
    "# Drop unnecessary columns\n",
    "metadata = metadata.drop(['disease'], axis=1)\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the metadata dataframe\n",
    "metadata.to_csv('data/mic_metadata.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('data/mic_metadata.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Due to the nature of single-cell data, we naturally have many cells from the same donor.\n",
    "#However, we cannot simply correlate the gene expression data in its current form. this would lead to within and outwith donor correlations.\n",
    "#Therefore, since we are working with single-cell data, this must first be pseudobulked in order to continue with the analysis.\n",
    "#This is important as it not only speeds up the computation, but most importantly negates the effects of within sample correlation.\n",
    "#Also, pseudobulking can help to mitigate the issues commonly found in single-cell data, such as drop outs and high zero value counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we shall sort out the metadata dataframe so that it only contains one row per donor since the data will be aggregated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert row names to a column named 'cell_id'\n",
    "metadata['cell_id'] = metadata.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'donor_id' and select the first row of each group\n",
    "rows = metadata.groupby('donor_id').first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract row indices corresponding to the first cell from each donor\n",
    "row_list = []\n",
    "for i, row in rows.iterrows():\n",
    "    row_idx = metadata.index.get_loc(row['cell_id'])\n",
    "    row_list.append(row_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns from the DataFrame\n",
    "metadata2 = metadata.iloc[row_list, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata2.set_index('donor_id', inplace = True, drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the cell_id column\n",
    "metadata2.drop(columns = 'cell_id', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the metadata\n",
    "metadata2.to_csv('data//mic_metadata_pseudobulk.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The metadata dataframe for the pseudobulk is now complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets proceed to aggregate the gene expression data.\n",
    "#This involves summing the gene expression data for each gene of each donor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First the gene expression matrix will need to be extracted from our mic adata object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since we are working with single-cell data which will be stored as a sparse matrix, this must be coerced into a dense matrix, so that it can be converted to a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the sparse matrix to a dense matrix\n",
    "dense_matrix = mic.X.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "datExpr = pd.DataFrame(dense_matrix, index=mic.obs_names, columns=mic.var_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "datExpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save datExpr\n",
    "#Save the metadata dataframe\n",
    "datExpr.to_csv('dataset/mic_datExpr_singlecell.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since highly variable genes capture the most informative genes, they will be used to filter the expression matrix further.\n",
    "#This is also a way to reduce the dimensionality of the data, so that downstream analyses may be more computationally efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "hvg = mic.var_names[mic.var['highly_variable']]\n",
    "hvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "datExpr = datExpr.loc[:,hvg]\n",
    "datExpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the donor_id column to the gene expression dataframe, so we know which cell came from which donor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index of 'datExpr' DataFrame to make the row names (cell names) a column\n",
    "datExpr_donor = datExpr.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "datExpr_donor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 'datExpr_reset' with 'metadata' on the 'index' and 'cell_id' columns\n",
    "datExpr_donor = pd.merge(datExpr_donor, metadata[['cell_id', 'donor_id']], left_on='index', right_on='cell_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "datExpr_donor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the cell names as the index again\n",
    "datExpr_donor.set_index('index', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "datExpr_donor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'cell_id' column if needed\n",
    "datExpr_donor.drop(columns=['cell_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "datExpr_donor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the expression matrix with donor_id\n",
    "datExpr_donor.to_csv('dataset/mic_datExpr_donorid_singlecell.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that we have our gene expression dataframe, it is now possible to aggregate the data for pseudobulking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate expression by donor ID (summing the values)\n",
    "pseudobulk_df = datExpr_donor.groupby('donor_id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudobulk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the pseudobulk expression matrix with donor_id\n",
    "pseudobulk_df.to_csv('dataset/mic_datExpr_pseudobulk.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We now have the pseudobulked data and the corresponding metadata dataframe to start the correlation network analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
